{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in certain industries, long-term reservations and then cancellations\n",
    "<br>\n",
    "\n",
    "Data source is from: \n",
    "<br>\n",
    "\n",
    "Helping to create more accurate predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Data separation__: \n",
    "<br>\n",
    "\n",
    "We want to keep everything consistent, and bring under the same framework\n",
    "<br>\n",
    "\n",
    "main issue: logreg needs first dummies dropped, decision tree does need all the dummies\n",
    "this is the nameing that we are going to use, `_logreg` is a data where the first dummies are dropped, `_dtree` where it is not. different models can be used, but these two are the main underlying ones, hence our naming decision\n",
    "\n",
    "- as a first step, we get an even sample of df, where prevalence = 0.5\n",
    "- `y` is the `IsCanceled` column of the data, `X_orig` is everything else\n",
    "- there are two differnt types of datasets that we need. for logreg, no full dummy, scaled, for dtree, full dummy, not scaled, we are calling these `_logreg` and `_dtree`\n",
    "- under both routes, we separate 3k observations for final testing (not to be touched until the end of the project with the final model), and 3k observations for validating each of the models\n",
    "- in summary, we will have six data - target pairs: `_train_logreg`, `_valid_logreg`, `_test_logreg`, `_train_dtree`, `_valid_dtree`, `_test_dtree`.  \n",
    "\n",
    "\n",
    "__Model selection__: \n",
    "<br>\n",
    "\n",
    "- for each model type, we are first using a `GridsearchCV` method with cross-validation being the same `cv` object, `roc_auc` being the score, parameters are model-specific, on the corresponding `_train` data\n",
    "- once we have a model, we consider the threshold we need to set - see Section 3.3 for more details\n",
    "- the chosen model of the specific type will be then fit on the whole X_train population, with the calculated hyperparameters\n",
    "- we check how well the model performs on the `_valid` datasets\n",
    "- we are calculating all the usual scores (accuracy, f1, auc, etc), but the score we will make our decision based on is the zweig_campbell score, which equals True Positive Rate - m * False Positive Rate\n",
    "- this process is repeated for the different model types, we pick the best one at the end, and compare how it performs against the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries, getting data in, creating databases, considering threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pydotplus\n",
    "from IPython.display import Image  \n",
    "\n",
    "from sklearn.metrics import SCORERS, precision_score, recall_score, \\\n",
    "    accuracy_score, f1_score, roc_curve, auc, confusion_matrix, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
    "    cross_validate, cross_val_predict, KFold, GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset\n",
    "df = pd.read_csv('H1_clean.csv')\n",
    "\n",
    "# get an even sample, get rows where cancel = 1, randomly select the same amount of cancel = 0, concat\n",
    "df_canc = df[df['IsCanceled'] == 1]\n",
    "rownum = len(df_canc)\n",
    "df_noncanc = df[df['IsCanceled'] == 0]\n",
    "df_noncanc = df_noncanc.sample(n = rownum)\n",
    "df = pd.concat([df_canc, df_noncanc])\n",
    "\n",
    "# set random seed, to be used for the whole project for reproducability\n",
    "random_seed = 12345\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# set cross-validation, to be kept fixed\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = random_seed)\n",
    "\n",
    "X_orig = df.drop('IsCanceled', axis = 1)\n",
    "y = df['IsCanceled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - First Dummies Dropped, Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to keep logreg data separate from the others,  significant portion is the dummies and we have to drop the first to avoid perfect linear dependence between columns. \n",
    "<br>\n",
    "\n",
    "Also, this type is scaled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X_orig, drop_first = True)\n",
    "\n",
    "# splitting first for train - test\n",
    "X_train_logreg, X_test_logreg, y_train_logreg, y_test_logreg = \\\n",
    "    train_test_split(\n",
    "        X, y, test_size=3000, random_state = random_seed\n",
    "    )\n",
    "\n",
    "# then, splitting for train - validation\n",
    "X_train_logreg, X_valid_logreg, y_train_logreg, y_valid_logreg = \\\n",
    "    train_test_split(\n",
    "        X_train_logreg, y_train_logreg, test_size = 3000, random_state = random_seed\n",
    "    )\n",
    "\n",
    "# finally, scaling\n",
    "scaler_logreg = StandardScaler()\n",
    "X_train_logreg = scaler_logreg.fit_transform(X_train_logreg)\n",
    "\n",
    "X_valid_logreg = scaler_logreg.transform(X_valid_logreg)\n",
    "X_test_logreg = scaler_logreg.transform(X_test_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - First Dummies Not Dropped, Not Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primarily for decision tree type of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X_orig, drop_first = True)\n",
    "\n",
    "# splitting first for train - test\n",
    "X_train_dtree, X_test_dtree, y_train_dtree, y_test_dtree = \\\n",
    "    train_test_split(\n",
    "        X, y, test_size=3000, random_state = random_seed\n",
    "    )\n",
    "\n",
    "# then, splitting for train - validation\n",
    "X_train_dtree, X_valid_dtree, y_train_dtree, y_valid_dtree = \\\n",
    "    train_test_split(\n",
    "        X_train_dtree, y_train_dtree, test_size = 3000, random_state = random_seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These should match, because we are using the same random seed. Wouldn't hurt the model's performance to keep these random, but just to check that we are indeed on the same split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train_dtree != y_train_logreg).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Selection Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking a threshold. \n",
    "<br>\n",
    "\n",
    "m = (1 - prevalence) / prevalence * (CFP - CTN) / (CFN - CTP)\n",
    "<br>\n",
    "\n",
    "we have a balanced set, so prevalence is around 0.5 -> first item is around 1\n",
    "<br> \n",
    "\n",
    "Cost item: two aspects: overbooking, financial analysis accuracy. In overbooking, the cost of assuming they will cancel when in reality they show up is higher than assuming they will be there and they won't, because presumably we need to pay compensation. It's questionable how often this happens with hotels though. In financial analysis, it could be more detremential to assume higher prfoits than to use a conservative one. So it is worse to assume they will come when in reality they won't, which means the false negative is worse. \n",
    "They are in opposite direction. So the prediction function can be changed depending on the use of the model. \n",
    "<br> \n",
    "\n",
    "For now, we use the model for the financial forecast, which means we need to apply a \"conservativism score\". We want to minimize FN's - if we say someone does not cancel, we better be sure. This is ultimately a judgement call, we will use 1 / 1.5 now. The cost of assuming that someone will come when in fact they will cancel is assumed to be 50% more than the opposite. This means the logregression would focus on getting the FPs out, m = 1/1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428607723577236"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = sum(y_train_logreg) / len(y_train_logreg)\n",
    "cost_ratio = 1/1.2\n",
    "m = (1 - prevalence) / prevalence * cost_ratio\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, longreg on Searching for best estimator with grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSCV Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=12345, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1, 10, 100, 1000, 10000],\n",
       "                         'max_iter': [100, 1000], 'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C':[1, 10, 10**2, 10**3, 10**4], \n",
    "    'max_iter':[100, 1000],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "gs_log = GridSearchCV(logreg, param_grid, scoring = 'roc_auc', cv = cv)\n",
    "\n",
    "gs_log.fit(X_train_logreg, y_train_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123475891064039"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_log.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_log.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best logreg is with `C` = 1000, `max_iter` = 100, `penalty` = `l2` from the first grid. Picking new iteration variables around these. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSCV Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=12345, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [500, 1000, 5000], 'max_iter': [50, 100, 500],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_2 = {\n",
    "    'C': [500, 1000, 5000], \n",
    "    'max_iter': [50, 100, 500],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "gs_log_2 = GridSearchCV(logreg, param_grid_2, scoring = 'roc_auc', cv = cv)\n",
    "\n",
    "gs_log_2.fit(X_train_logreg, y_train_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123479076917864"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_log_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_log_2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting how max iteration goes down. There is no significant change in the AUC, and the lower the max_iter, the simpler the model is. However, with lower `max_iter`, we risk the model not to converge, keeping it at 50. \n",
    "<br>\n",
    "\n",
    "No significant improvement, we are keeping it here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_C = gs_log_2.best_estimator_.C\n",
    "chosen_max_iter = gs_log_2.best_estimator_.max_iter\n",
    "chosen_penalty = gs_log_2.best_estimator_.penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Chosen Model & Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9144915498643965"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_chosen = LogisticRegression(\n",
    "    C = chosen_C, max_iter = chosen_max_iter, penalty = chosen_penalty, solver = 'liblinear'\n",
    "    )\n",
    "\n",
    "logreg_chosen.fit(X_train_logreg, y_train_logreg)\n",
    "\n",
    "y_train_prediction_probabilities_logreg = logreg_chosen.predict_proba(X_train_logreg)\n",
    "\n",
    "fpr_train_logreg, tpr_train_logreg, thresholds_train_logreg = \\\n",
    "    roc_curve(y_train_logreg, y_train_prediction_probabilities_logreg[:,1])\n",
    "\n",
    "auc(fpr_train_logreg, tpr_train_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs a bit better on the whole data set, 0.912 above was from a cross-validated score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43484214452380127"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zweig_campbell_scores_train_logreg = \\\n",
    "    tpr_train_logreg - m * fpr_train_logreg\n",
    "\n",
    "chosen_threshold_logreg = \\\n",
    "    thresholds_train_logreg[np.argmax(zweig_campbell_scores_train_logreg)]\n",
    "\n",
    "chosen_threshold_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the probability of canceling is above that, we say it is going to be cancelled. (So there is a relatively higher chance of classifying something as being cancelled.)\n",
    "\n",
    "Calculating train predictions in case we ever want to do a stacking model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prediction_logreg = (y_train_prediction_probabilities_logreg[:,1] > chosen_threshold_logreg) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are checking the overfitting, calculating final test scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_prediction_probabilities_logreg = \\\n",
    "    logreg_chosen.predict_proba(X_valid_logreg)\n",
    "\n",
    "fpr_valid_logreg, tpr_valid_logreg, thresholds_valid_logreg = \\\n",
    "    roc_curve(y_valid_logreg, y_valid_prediction_probabilities_logreg[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1e8797d0>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xU9Z3/8dcnM7mTQEJIEAKEQEDjpaIR8VIva4tgW7Hb2mLX7q9dVntz225rt+6vXWvttlvb39bq/uxWfrZr628rtbVaarHWeqmWhyAoFxVEIyJEEMIthJDbzHz2jxNCEgIZYJLJzLyfjwePc52Zz8nlncM53/P9mrsjIiKpLyvZBYiISGIo0EVE0oQCXUQkTSjQRUTShAJdRCRNhJP1wWVlZV5VVZWsjxcRSUkvvPDCTncf09+2pAV6VVUVK1euTNbHi4ikJDN760jbdMlFRCRNKNBFRNKEAl1EJE0o0EVE0oQCXUQkTQwY6Gb2UzPbYWYvH2G7mdmdZlZvZmvN7KzElykiIgOJ5wz9XmDOUbbPBWq6/l0P/OeJlyUiIsdqwHbo7v6MmVUdZZd5wM896Id3mZmNMrOT3H1bgmoUkSHm7kRiTiTqdMZitHfG6IjGiMWcaMyJuuPuRGMQjTkxd1p3NZDXVE9k+wai4XwccA/ey4FYDBzHYhFG7dtAW7gYB/a3RcjPDh29nkQcUzzvMkS9iZeeNY9pZ12c8PdNxINF44EtPZYbutYdFuhmdj3BWTwTJ05MwEeLpLfWjiitnVGa2zrpjMa6QzbmTiTSAW3N7D3QAcDbe1vJCWWRc2A7RDuIxmK0dcZoau0gNztEJOrBuo5OSlo3U96xmRYrwGPQuL+dLAvC+UBH9LA6TsnazMm2me1ecti2fGvnnKzXjuv4Ym7H9bpUt6L4JBimgd7fd6Tfv3PuvhBYCFBXV6eRNSR1RTth39vQ2dZ7tQeB2BGN0hmJ0dIRhaatdHa2sWt/B2W7XqD5QCtjW16lmRGMO7CO/Vkj6Ywd+nWIxoKzY4BY7PBfkwI6qM56Z/COLfvIm6aEdtFUPB3r+q03wChgf2QKkVAh+ydcTGfl+cRGTSQvOxszCBlkmWEGWVkWzGfnY0XlZJkRMiM7NHCwmx19n3j+NAzwFnF9TiKcO0jvm4hAbwAm9FiuBLYm4H1FEqupAXa90eu32t2JOYcuI+xYj29fz4GWZgreXsr+3ApGNdcTsRARC5KuILqfbDr7/YgQUBRHKW2eTaV18rpNojS6h02h6XREYxTmhAllGzF38sJZ5OeEyQ4ZWVmGu5MTDmHArmg10ZyRRArKaSuaRHY4i4LsEDnhLMLRViitJpRTQCjrYJj2CalYBEbXwMjK+FIOIJxH2IzRR9llVHzvJIMkEYG+GLjBzBYR/OFp0vVzSajOVtj+SjAf7YDHb4byU4Ll3W8GZ8vhXDzSDltXESkopzMGkZhT3Npw1Lc2ghDuewW3sGsaa2tmeWwq5baXF3waJfnZWLZR7PvZFyphU8409naGqCzJpzg/m3CW0R6JUjYil3CWEYnByLwQ4cISPK+EshG5hMbWUjKyGEJZ1HR9zgWJ+UpJhhsw0M3sfuASoMzMGoBv0PWfMnf/MbAEuAKoBw4AnxysYiVN7d4IyxcCDjvW42+/SKx4PKGdrxLLyiYr1s/ZcMMKGq2ULI8xmr2s9qlEPIsCxrKvqYCtfvA8sopy9vBS1skU5WZxIBpmV9nZtLRHmViaT252iMKcMOFQ8F//kMGB4ipGlU+iqqyAsSPzeXdOCDPj5KH8mogch3hauVwzwHYHPpewiiStRFr3EXv6e3jDCvbnjKGlPUJrZ5SOSIzT9/yp177tZBPxLAqtnbd27GWDn0NJbD9rY9VEyWIltURjTsWoQtbmnk1Le4TKknzCoSwmjy5gZH42nTHnpJF5lI3IZXJZIeVFuRTlZXNhWM/QSfpLWve5kj7cnW2bXmX76y+wun4L0/Y9x/a2LGb5GsbZ7u79coG9sZMIE/zgbbEKOi2b16nkhZyZLB85h+wso6qskNGFOUwuKyR/ZB6zCnOYVFrIZwqOcrdORBToEqf9O2DL89C0BV77A2x8GoB2cgh7J+PMGQfM6PGS7dnjeDP7VJrLzuK16o8THXESE0oLmFBSQEVxHjldZ83VwOVDfTwiaUiBLr0t+Sd48xkI5/Zu/bB11WG77vIiloQvIy8cYuLIEKVTzmb0hOmUVEzCSidT0eP1ZwxF7SIZToEuh/zlh/D83cH8lMvodGN3SwdNrZ205NSxuTWHuyPvZ48XYcXj+PePzuDa6tIhabcrIgNToGeinfXw4s+C+VX3QX4p7H6je/Oy2q/z3cbzWb1lb/e64rwwV549jo+NLWbOaWMpG5E71FWLyAAU6Jki2gnL74Y/fu2wTd66l2X5F5N9YDt3dF7Fsy/WkhPex9TyEVx/UTXvrinjpJH5SShaRI6FAj2d7XgVHv0KbF4O0fZem2J/9Q3u3H8JT7y2l5feaYU2eHdNGbOqR/MvtRVUlxUSDqmpn0gqUaCno/b9QUuUBxcEy2NOgfZmDky6hIcK57PNyvntsrfZsjt4oPcjdZV89JwJnD2pNIlFi8iJUqCnizefgdX3w84N8PYL3atjY89g+XseYukbu/i/T9UD+4B9VJbk8/X3ncKCCyfrpqZImlCgp7KXfwN/+GfY37vnPQ/n805BDXfmfppFm4rxe5YDQSvEL1xWw6cvnkLeAP1Pi0jqUaCnmn3b4Af99Coy9nR2Vn+Qz2w8jxWb9sD+YPWFU8u4aFoZ7z9jHONG6camSDpToKeS5/8fLLnx0PLpH8HPWcCSvZNYtGIzzz65E9jD+VNGc+n0cj5+3iSdiYtkEAV6KmjeDr/9HNQ/HizXXgVX38tPlm7iWz9aB+wCoKZ8BP/216dTV6WbmyKZSIE+XDVvh/vnQ04hbHr20Po5t9F85gK++/DL/PfyzQB86b3T+PisSZQU5iSpWBEZDhTow03LTvj+lN7rJsyC8lNofs9t3POXt7jjlj8CMKogmz984SLGjsxLQqEiMtwo0IeTprfh9tpDy+d+BmZ/C0LZ3PPsRv71m0H/4VPLR3Dj7GlcfupYNTkUkW4K9OGgdQ/86RZ44d5D625pAqCtM8qdj7/Kj54O+lq5ae7JfOqiagW5iBxGgZ5Mv/tC7xAHmHMbnP0JADa808zcO54h5lBZks/9181iQmnBkJcpIqlBgZ4M7vDNHuOj5xbD+Z+H6XNh7Gm8tauFWxY/z1MbGgGYe9pYfvQ3Z+msXESOSoE+1Pa8BXf0GO7hcytgzLTuxRt+8SKPrA36WDl1XDG3zjtVfayISFwU6EOtZ5h/dRPkl3Qvfv+xV7vD/P8vOJcLa8qGuDgRSWUK9KES7YSfzA7mC8vhyxsg61D3tP/y8Mvct+wtak8q5jefPV9PeIrIMVOgD4XWvXDbpEPLc2/rDvM9LR3M+FbwBOgH3jWO2z50usJcRI6LAn0oHAzzEWPhi2uDAZiBx9dt5wuLgsGXRxVkc8dHzyQrSzc+ReT4KNAHkzssvePQ8pdfBTPcncVrtvKFRasJZRkPffZ8ZkwsOfL7iIjEQYE+GHa/CXee2XvdVf8JZvz5tUb+/mcr6Iw6BTkhHvrsBUwfW5ScOkUkrSjQE23FT+D3Xwrmw3lQOw8u/w7tuSX84NH13P3njQD8/YWT+fLs6eTn6Hq5iCSGAj2R9u84FOZT3wPXPghANOZcetuTbG1qIy87i9985gJqxxUnsVARSUcK9ERZvhAe/Uowf94NcPm3uzc9+GIDW5va9MSniAyqrIF3kQE1bjgU5lMug0u/1r2ppT3CP/16LUW5Yf7jmhkKcxEZNDpDP1HRCNw1M5h/3w/gnAXdmza808zlP3wGgOsvqiYc0t9PERk8cSWMmc0xsw1mVm9mN/WzfaKZPWVmq8xsrZldkfhSh6mfXxlMc4vhrL/tXu3u3WE+78xxfO7SqcmoTkQyyICBbmYh4C5gLlALXGNmtX12+zrwgLvPAOYDP0p0ocNS8zvw1tJg/gtrIJTdven//HEDANfMnMgd82fogSERGXTxnKHPBOrdfaO7dwCLgHl99nHgYLONkcDWxJU4jG1bG0zP/TQUHOoR8bXtzdz11BuEsoxvX3VakooTkUwTT6CPB7b0WG7oWtfTLcC1ZtYALAH+ob83MrPrzWylma1sbGw8jnKHkdX3wy+uDubP/Fj36taOKLNvDy61/PvV79KZuYgMmXgCvb9E8j7L1wD3unslcAVwn5kd9t7uvtDd69y9bsyYMcde7XAQi8Ev5sPDnw6WS6uh4nQA9rdHOPPWYADna2ZO4KoZff/uiYgMnngCvQGY0GO5ksMvqSwAHgBw9+eAPCA9O/N+7J/htUeD+bM/AZ9f1d1z4lcfXEt7JMYnzq/i21ednrwaRSQjxdNscQVQY2aTgbcJbnp+rM8+m4HLgHvN7BSCQE/xayr92LoKlv84mP/6ju5eEwFuf/w1fr92G+dUlfCND9SqvbmIDLkBz9DdPQLcADwGrCdozfKKmd1qZl1t9vgycJ2ZrQHuBz7h7n0vy6S2p78LCy8J5rMLeoX5Uxt2cMcTr1NelMt9C85VmItIUsT1YJG7LyG42dlz3c095tcBFyS2tGFm+d3BtM/DQwCf++8XAXjk8xdqcAoRSRo9uhiPZf8JrbshnH9YmN+79E0OdET50FmVlBflJalAEREFenz+0PVw7NX/ddimby9ZD8DX3nfKUFYkInIYBfpAfn5VMC0aB9Pn9tp07T3L6Yw6nzi/itLCnCQUJyJyiAJ9IFueD6affa7X6idf3c5f6ndSUZzLze/v2xOCiMjQU6Afzcu/gc4WGDUR8kd1r16zZS9/d+9KABZdf56eBhWRYUGBfiTvvAy//mQwf94N3avdnWvvWQ7Aj689m8llhcmoTkTkMAr0/jQ1wI+7WmFe/h0491Pdm259ZB3N7RFuuHQqc04bm6QCRUQOp0Dvz5++GUwLy+G8z/Xa9F9LNwHwpfdOG+KiRESOToHen5ceCKY3vtZr9UOrGgCYc+pYXTcXkWFHgX4k+SXQ4xF+d+fLD6why+CH889MYmEiIv1ToPf15L8G07q/67X69sdfI+bwqYun6PF+ERmWFOh9vfCzYFpzefcqd+fOJ+spyg3zldnTk1SYiMjRKdB7isWgZQdMmAUTz+1e/cM/vQ7AlPIRunYuIsOWAr2n5q5xO8bN6F51oCPCHU8Egf6zv5uZjKpEROKiQO9p37ZgWlbTvWrhMxsBuHXeqYzMz05GVSIicVGg9/TKQ8F01EQAojHnvufeIiecxd+cOymJhYmIDEyBftCeTbDsrmB+7BkAPLF+O7taOvjfc08mpGvnIjLMKdAPevDvg+mpH4SiCgBu/NUaAK4446RkVSUiEjcF+kENK4Lp1fcCsK+tk31tEUbmZ2skIhFJCQp0gEf+MZiOntq96h8XrQZQX+cikjIU6ABvPBVMFzwOQFtnlCde3cHs2go+dHZlEgsTEYmfAh1g/3bIL4WCUgBuWfwKABfWlCWzKhGRY6JA37QUOg/ApPMBeKmhiUUrtjCzqpSPz1JTRRFJHQr0V38fTM/4KAD/8WTwVOh3/vp0zNRUUURShwL9wK5gWnsl0Zjzx3XbKRuRy9TyEcmtS0TkGCnQt63pnv3iL4OWLZ+8oCpJxYiIHD8FeuN6KK6kMxrjd2u2kpedxacuqk52VSIixyyzA333m8F03Jms2rwXgBtnTyccyuwvi4ikpsxOrhd/HkyrL+GXK7YAUDuuOHn1iIicgMwO9IYVYFkw8zoefLGB0sIczqseneyqRESOS1yBbmZzzGyDmdWb2U1H2OcjZrbOzF4xs18ktsxBsulZ8BhNrZ0AXF1XqaaKIpKywgPtYGYh4C7gvUADsMLMFrv7uh771AD/DFzg7nvMrHywCk6oUA7UzOaJ9dsBmFlVmuSCRESOXzxn6DOBenff6O4dwCJgXp99rgPucvc9AO6+I7FlDoJIB0Q7oKSKdVv3AXDJ9NT4OyQi0p94An08sKXHckPXup6mAdPMbKmZLTOzOf29kZldb2YrzWxlY2Pj8VWcKA9dD4C7c89f3mRq+QgNYiEiKS2eQO8v5bzPchioAS4BrgHuMbNRh73IfaG717l73ZgxY4611sRx7x5u7s8VHwfgr07W2bmIpLZ4Ar0BmNBjuRLY2s8+v3X3Tnd/E9hAEPDD0676YDrmZJ54KwrAR8+ZcJQXiIgMf/EE+gqgxswmm1kOMB9Y3Gefh4FLAcysjOASzMZEFppQK38KQNu7b+K+ZW9x1sRRVJcVJrkoEZETM2Cgu3sEuAF4DFgPPODur5jZrWZ2ZddujwG7zGwd8BTwFXffNVhFnxB3WPYjAP68uwSAD589Qc0VRSTlDdhsEcDdlwBL+qy7uce8A1/q+je8HdgdTGsu5xcbC4AW3ltbkdSSREQSIfOeFN2zKZhOvojmtuCBojFFucmrR0QkQTIv0BvXB9OyaeSGQ+r3XETSRuYF+l9+CICPrGTD9mamjNHNUBFJD5kV6Bv+ALuCIeaWt1Swu6WDGRNLklyUiEhiZFagr7ovmM79Pvc8G/SFfv4U9a4oIukhswI9nBdMZ17HM68FXQ+cNm5kEgsSEUmczAp0gNIpbG1qoyMaY8GFk8lS/y0ikibiaoeeNra+CO4srd8JqP8WEUkvmRPokQ7YvRGysnlgZdB55Kkabk5E0kjmXHJ5Zy0AOyZfyYpNe5hVXcqogpwkFyUikjiZE+jtzQC8UHARAF9/X20yqxERSbjMCfS9mwHY2pYNQLUeKBKRNJMZge4Ov/s8AOua8ynMCVGQkzm3D0QkM2RGoL/yGwAioXwe3JTLB941LskFiYgkXmYE+opgQItvV94NwI2XT09mNSIigyIzrjt0DV6xaGMu1WPyKBuh7nJFJP2k/xl62z7Y9CztpSfT2hnl/WfocouIpKcMCPS9AKyyUwB43+knJbMaEZFBk/6B/vBnAfj93okATB9blMxqREQGTfoH+qZnAfhVy5kazEJE0lp6B/r+oIvclqLJtJGr6+ciktbSO9BX3APAo4VXAfDe2opkViMiMqjSO9Db9wHwnYbTKcwJcdp4DWYhIukrvQN92xo8nM/uSB4TSguSXY2IyKBK7weL3lrKwfGIbpytp0NFJL2l7xl6V++KmwrPAGBahZorikh6S99Af/E+AO5uuYiq0QVMHK1LLiKS3tI30NcsAuDZ9qnMqh6d5GJERAZf+gZ6QSntoUIavFzd5YpIRkjfQMd5KRQMM6czdBHJBOkZ6G37YNsaWltbuWDqaEJZNvBrRERSXFyBbmZzzGyDmdWb2U1H2e/DZuZmVpe4Eo/D0/8GwE5Gcv6UsqSWIiIyVAYMdDMLAXcBc4Fa4Bozq+1nvyLg88DyRBd5zFp2AnBz5yc5Wb0rikiGiOcMfSZQ7+4b3b0DWATM62e/bwHfA9oSWN+xa90LLz1AU6iEZgo4V9fPRSRDxBPo44EtPZYbutZ1M7MZwAR3f+Rob2Rm15vZSjNb2djYeMzFxuW2SQAcsBEAjMhN74dhRUQOiifQ+7uj6N0bzbKA24EvD/RG7r7Q3evcvW7MmDHxVxmvN57qnj1v/3c5a+KoxH+GiMgwFU+gNwATeixXAlt7LBcBpwFPm9kmYBawOCk3RhtWAPDMOXcBpvbnIpJR4gn0FUCNmU02sxxgPrD44EZ3b3L3MnevcvcqYBlwpbuvHJSKj6b+CQB+tz/oiOuDM8YfbW8RkbQyYKC7ewS4AXgMWA884O6vmNmtZnblYBcYt1gMtiwDC/H6zg5KCrIZVZCT7KpERIZMXHcM3X0JsKTPupuPsO8lJ17WcWjdHXx+RS2rN+3lI3WVSSlDRCRZ0u5J0S1VVwNQUZyX5EpERIZW2gX6pl0tAFx+6tgkVyIiMrTSJ9Dv+yAAz72xmyljCjV+qIhknPQI9GgE3lkLwG8OvIszJ5QkuSARkaGXHoG++TkANk26mu2UqrmiiGSk9Aj0dQ8D8PPmswGoqRiRzGpERJIi9Ts66WyDFfcA8GjLNMaPMrVwEZGMlPpn6K8e6g9sW1MbV83Q4/4ikplSP9Cb3wHg9xf9FoDT1bpFRDJU6gf6k98C4NWmbABmTlb/5yKSmVI70N0hEoyn8afNMcaPyqe0UP23iEhmSu1A/+PXAfBTP8jGxv2cPUntz0Ukc6V2oEfaAXh6yldpj8SYObk0yQWJiCRPagd6/eOQW8ya3SEA3l1TluSCRESSJ7UDPW8kxCL8bk0wgNLE0oIkFyQikjypHejb1hAZdxZvNLZw8tgizPob/lREJDOkdqAD+6wYgHlnqv8WEclsqRvozdsB2BgpB+CS6WOSWY2ISNKlbqBvXQXA41uCxZpydcglIpktdQP9kS8CsLyjmoriXMKh1D0UEZFESN0UzA2una/2qVwwVc0VRURSN9BDOTRUXArAB85QD4siIqkb6MCBjigAF0/TDVERkZQO9GjMKcgJkZWl9uciIikd6E0HOgkrzEVEgFQNdHfY/hIt7Z2Ua7g5EREgVQM9Flw77/QszlUPiyIiQKoGepeXY1UU52cnuwwRkWEhpQMdYEKJelgUEYFUDfTdGwHIt3YqS/KTXIyIyPAQV6Cb2Rwz22Bm9WZ2Uz/bv2Rm68xsrZk9YWaTEl9qD68/BsArsSqmVRQN6keJiKSKAQPdzELAXcBcoBa4xsxq++y2Cqhz9zOAXwPfS3ShvbzzEgDPx06hojh3UD9KRCRVxHOGPhOod/eN7t4BLALm9dzB3Z9y9wNdi8uAysSW2UfLTgDCI0ZrUAsRkS7xBPp4YEuP5YaudUeyAHi0vw1mdr2ZrTSzlY2NjfFX2de21ezzAk4ZX3L87yEikmbiCfT+ToG93x3NrgXqgO/3t93dF7p7nbvXjRlz/P2veH4J630ikVi/ZYiIZKRwHPs0ABN6LFcCW/vuZGbvAb4GXOzu7Ykpr3+dUWj0UUwZo0EtREQOiucMfQVQY2aTzSwHmA8s7rmDmc0A7gaudPcdiS+zt4Nn5nVVuuQiInLQgIHu7hHgBuAxYD3wgLu/Yma3mtmVXbt9HxgB/MrMVpvZ4iO8XUJ0RGIAVOqhIhGRbvFccsHdlwBL+qy7ucf8exJc11G1R4K+XKpGK9BFRA5KySdFo12XXEYV5CS5EhGR4SMlA721M0pedkqWLiIyaFIvFaMRpthWcsOhZFciIjKspF6gN6wAYHy4KcmFiIgMLykX6B2dHQA8Pe66JFciIjK8pGCgBy1cKjT0nIhILykX6Ade/zMA2dkaqUhEpKeUC/R9saCpYvvovj34iohktpQL9D0twTX0aSeNTHIlIiLDS8oFenYoKLkoL66HXEVEMkbKBfpBGtZCRKS3lA10ERHpLeUC/eCQFhp5TkSkt5QL9IOJbrroIiLSS8oFuh9KdBER6SHlAv0g5bmISG8pG+giItJbygX6wZuiOkUXEekt5QJdN0VFRPqXeoHeRXEuItKbAl1EJE2kXKC7D7yPiEgmSr1A77qIbnpUVESkl5QL9IMU5yIivaVcoB+85KITdBGR3lIu0A9Ss0URkd5SNtCV5yIivaVcoKuRi4hI/1Iu0A/SNXQRkd5SL9DVe66ISL9SLtDVDl1EpH9xBbqZzTGzDWZWb2Y39bM918x+2bV9uZlVJbrQwz5zsD9ARCTFDBjoZhYC7gLmArXANWZW22e3BcAed58K3A7cluhCRUTk6OI5Q58J1Lv7RnfvABYB8/rsMw/4Wdf8r4HLbJCuiWiQaBGR/sUT6OOBLT2WG7rW9buPu0eAJmB03zcys+vNbKWZrWxsbDyugvMqpvHiiIsJhcPH9XoRkXQVTyr2dy7ctzl4PPvg7guBhQB1dXXH1aR8xuxrYfa1x/NSEZG0Fs8ZegMwocdyJbD1SPuYWRgYCexORIEiIhKfeAJ9BVBjZpPNLAeYDyzus89i4H91zX8YeNJdPZeLiAylAS+5uHvEzG4AHgNCwE/d/RUzuxVY6e6LgZ8A95lZPcGZ+fzBLFpERA4X151Fd18CLOmz7uYe823A1YktTUREjkXKPSkqIiL9U6CLiKQJBbqISJpQoIuIpAlLVutCM2sE3jrOl5cBOxNYTirQMWcGHXNmOJFjnuTuY/rbkLRAPxFmttLd65Jdx1DSMWcGHXNmGKxj1iUXEZE0oUAXEUkTqRroC5NdQBLomDODjjkzDMoxp+Q1dBEROVyqnqGLiEgfCnQRkTQxrAN9OA5OPdjiOOYvmdk6M1trZk+Y2aRk1JlIAx1zj/0+bGZuZinfxC2eYzazj3R9r18xs18MdY2JFsfP9kQze8rMVnX9fF+RjDoTxcx+amY7zOzlI2w3M7uz6+ux1szOOuEPdfdh+Y+gq943gGogB1gD1PbZ57PAj7vm5wO/THbdQ3DMlwIFXfOfyYRj7tqvCHgGWAbUJbvuIfg+1wCrgJKu5fJk1z0Ex7wQ+EzXfC2wKdl1n+AxXwScBbx8hO1XAI8SjPg2C1h+op85nM/Qh9Xg1ENkwGN296fc/UDX4jKCEaRSWTzfZ4BvAd8D2oayuEESzzFfB9zl7nsA3H3HENeYaPEcswPFXfMjOXxktJTi7s9w9JHb5gE/98AyYJSZnXQinzmcAz1hg1OnkHiOuacFBH/hU9mAx2xmM4AJ7v7IUBY2iOL5Pk8DppnZUjNbZmZzhqy6wRHPMd8CXGtmDQTjL/zD0JSWNMf6+z6guAa4SJKEDU6dQuI+HjO7FqgDLh7UigbfUY/ZzLKA24FPDFVBQyCe73OY4LLLJQT/C3vWzE5z972DXNtgieeYrwHudfd/N7PzCEZBO83dY4NfXlIkPL+G8xl6Jg5OHc8xY2bvAb4GXOnu7UNU22AZ6JiLgNOAp81sE8G1xsUpfmM03p/t37p7p7u/CWwgCPhUFc8xLwAeAHD354A8gk6s0lVcv+/HYjgHeiYOTj3gMXddfribIMxT/boqDHDM7t7k7mXuXuXuVQT3Da5095XJKTch4vnZfpjgBjhmVkZwCWbjkFaZWPEc82bgMgAzO4Ug0BuHtMqhtRG8weAAAAC2SURBVBj4267WLrOAJnffdkLvmOw7wQPcJb4CeI3g7vjXutbdSvALDcE3/FdAPfA8UJ3smofgmP8EbAdWd/1bnOyaB/uY++z7NCneyiXO77MBPwDWAS8B85Nd8xAccy2wlKAFzGpgdrJrPsHjvR/YBnQSnI0vAD4NfLrH9/iurq/HS4n4udaj/yIiaWI4X3IREZFjoEAXEUkTCnQRkTShQBcRSRMKdBGRNKFAFxFJEwp0EZE08T85g8r7kLR+pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_train_logreg, tpr_train_logreg)\n",
    "plt.plot(fpr_valid_logreg, tpr_valid_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction with chosen threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_prediction_logreg = \\\n",
    "    (y_valid_prediction_probabilities_logreg[:,1] > chosen_threshold_logreg) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO PUT IN SEPARATE .PY FILE\n",
    "\n",
    "def calculate_scores(y_train_true, y_train_pred, y_valid_true, y_valid_pred, m, verbose = False):\n",
    "    \"\"\"\n",
    "    calculates scores, updates dictionary with relevant scores\n",
    "    if verbose is true, also prints out results\n",
    "    returns a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    scoring_dictionary = {}\n",
    "    \n",
    "    scoring_dictionary['train_accuracy'] = accuracy_score(y_train_true, y_train_pred)\n",
    "    scoring_dictionary['validation_accuracy'] = accuracy_score(y_valid_true, y_valid_pred)\n",
    "    scoring_dictionary['train_f1'] = f1_score(y_train_true, y_train_pred)\n",
    "    scoring_dictionary['validation_f1'] = f1_score(y_valid_true, y_valid_pred)\n",
    "    scoring_dictionary['train_auc'] = roc_auc_score(y_train_true, y_train_pred)\n",
    "    scoring_dictionary['validation_auc'] = roc_auc_score(y_valid_true, y_valid_pred)\n",
    "    scoring_dictionary['train_zweigcampbell'] = \\\n",
    "        calculate_zweig_campbell_score(y_train_true, y_train_pred, m)\n",
    "    scoring_dictionary['validation_zweigcampbell'] = \\\n",
    "        calculate_zweig_campbell_score(y_valid_true, y_valid_pred, m)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Train accuracy : \" + str(scoring_dictionary['train_accuracy']))\n",
    "        print(\"Validation accuracy : \" + str(scoring_dictionary['validation_accuracy']))\n",
    "        print(\"Train F1 : \" + str(scoring_dictionary['train_f1']))\n",
    "        print(\"Validation F1 : \" + str(scoring_dictionary['validation_f1']))\n",
    "        print(\"Train AUC : \" + str(scoring_dictionary['train_auc']))\n",
    "        print(\"Validation AUC : \" + str(scoring_dictionary['validation_auc']))\n",
    "        print(\"Train Zweig-Campbell : \" + str(scoring_dictionary['train_zweigcampbell']))\n",
    "        print(\"Validation Zweig-Campbell : \" + str(scoring_dictionary['validation_zweigcampbell']))\n",
    "        \n",
    "    return scoring_dictionary\n",
    "    \n",
    "    \n",
    "def calculate_zweig_campbell_score(y_true, y_pred, m):\n",
    "    \"\"\"\n",
    "    calculates tpr - m * fpr\n",
    "    \"\"\"\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    fpr = fp / (fp + tn)\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    return tpr - fpr * m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.8421119110774283\n",
      "Validation accuracy : 0.8516666666666667\n",
      "Train F1 : 0.8507819028291752\n",
      "Validation F1 : 0.8615001556178026\n",
      "Train AUC : 0.8424693839181233\n",
      "Validation AUC : 0.8508712660028449\n",
      "Train Zweig-Campbell : 0.7195757113821138\n",
      "Validation Zweig-Campbell : 0.7345506545337057\n"
     ]
    }
   ],
   "source": [
    "logreg_scores = calculate_scores(\n",
    "    y_train_logreg, y_train_prediction_logreg, \n",
    "    y_valid_logreg, y_valid_prediction_logreg, \n",
    "    m, verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, longreg on Searching for best estimator with grid search. \n",
    "\n",
    "`class_weight`: we use this to encounter for the cost imbalance, as decided above, FN has a higher cost for us, than FP. class 0 (IsCanceled = 0) has a higher cost in our case, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(class_weight = {0: 1, 1: cost_ratio})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSCV Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=12345, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                              class_weight={0: 1,\n",
       "                                                            1: 0.8333333333333334},\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 5, 10, 20, 50],\n",
       "                         'max_features': [5, 10, 20, 50],\n",
       "                         'min_samples_leaf': [5, 10, 20, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth':[2, 5, 10, 20, 50], \n",
    "    'min_samples_leaf':[5, 10, 20, 50],\n",
    "    'max_features': [5, 10, 20, 50]\n",
    "}\n",
    "\n",
    "gs_dtree = GridSearchCV(dtc, param_grid, scoring = 'roc_auc', cv = cv)\n",
    "\n",
    "gs_dtree.fit(X_train_dtree, y_train_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9345732523038495"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                       class_weight={0: 1, 1: 0.8333333333333334},\n",
       "                       criterion='entropy', max_depth=20, max_features=50,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=20,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       presort='deprecated', random_state=None,\n",
       "                       splitter='best')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtree.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limiting factor is probably the `min_sample_leaf`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSCV Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=12345, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                              class_weight={0: 1,\n",
       "                                                            1: 0.8333333333333334},\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [15, 20, 30],\n",
       "                         'max_features': [30, 50, 65],\n",
       "                         'min_samples_leaf': [15, 20, 30]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_2 = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth':[15, 20, 30], \n",
    "    'min_samples_leaf':[15, 20, 30],\n",
    "    'max_features': [30, 50, 65]\n",
    "}\n",
    "\n",
    "gs_dtree = GridSearchCV(dtc, param_grid_2, scoring = 'roc_auc', cv = cv)\n",
    "\n",
    "gs_dtree.fit(X_train_dtree, y_train_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9366248308500268"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                       class_weight={0: 1, 1: 0.8333333333333334},\n",
       "                       criterion='entropy', max_depth=15, max_features=65,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=20,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       presort='deprecated', random_state=None,\n",
       "                       splitter='best')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_dtree.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, not much increase, keeping the parameters as they are, limiting max_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Chosen Model & Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_criterion = gs_dtree.best_estimator_.criterion\n",
    "chosen_max_depth = gs_dtree.best_estimator_.max_depth\n",
    "chosen_min_samples_leaf = gs_dtree.best_estimator_.min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676925125034972"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_chosen = DecisionTreeClassifier(\n",
    "    criterion = chosen_criterion, max_depth = chosen_max_depth, \n",
    "    min_samples_leaf = chosen_min_samples_leaf\n",
    "    )\n",
    "\n",
    "dtree_chosen.fit(X_train_dtree, y_train_dtree)\n",
    "\n",
    "y_train_prediction_probabilities_dtree = dtree_chosen.predict_proba(X_train_dtree)\n",
    "\n",
    "fpr_train_dtree, tpr_train_dtree, thresholds_train_dtree = \\\n",
    "    roc_curve(y_train_dtree, y_train_prediction_probabilities_dtree[:,1])\n",
    "\n",
    "auc(fpr_train_dtree, tpr_train_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zweig_campbell_scores_train_dtree = \\\n",
    "    tpr_train_dtree - m * fpr_train_dtree\n",
    "\n",
    "chosen_threshold_dtree = \\\n",
    "    thresholds_train_dtree[np.argmax(zweig_campbell_scores_train_dtree)]\n",
    "\n",
    "chosen_threshold_dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prediction_dtree = (y_train_prediction_probabilities_dtree[:,1] > chosen_threshold_dtree) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_prediction_probabilities_dtree = \\\n",
    "    dtree_chosen.predict_proba(X_valid_dtree)\n",
    "\n",
    "fpr_valid_dtree, tpr_valid_dtree, thresholds_valid_dtree = \\\n",
    "    roc_curve(y_valid_dtree, y_valid_prediction_probabilities_dtree[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2048f710>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_train_dtree, tpr_train_dtree)\n",
    "plt.plot(fpr_valid_dtree, tpr_valid_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_prediction_dtree = \\\n",
    "    (y_valid_prediction_probabilities_dtree[:,1] > chosen_threshold_dtree) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.8949728432487053\n",
      "Validation accuracy : 0.8713333333333333\n",
      "Train F1 : 0.8974659350144892\n",
      "Validation F1 : 0.8754034861200775\n",
      "Train AUC : 0.8951399674367881\n",
      "Validation AUC : 0.8710526315789473\n",
      "Train Zweig-Campbell : 0.811377879403794\n",
      "Validation Zweig-Campbell : 0.7656761473042362\n"
     ]
    }
   ],
   "source": [
    "dtree_scores = calculate_scores(\n",
    "    y_train_dtree, y_train_prediction_dtree, \n",
    "    y_valid_dtree, y_valid_prediction_dtree, \n",
    "    m, verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra models that did not make the cut due to different considerations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try one first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(metric = 'minkowski')\n",
    "\n",
    "parameters_knn = {'n_neighbors': [3, 5, 9], 'p': [1,2,3]}\n",
    "\n",
    "gscv_knn = GridSearchCV(knn, param_grid = parameters_knn, cv = cv, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=12345, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [3, 5, 9], 'p': [1, 2, 3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runs for approx. 10 minutes\n",
    "gscv_knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the lowest possible neighbor worked (want to keep it an odd number, n = 1 would be very overfit).\n",
    "Running with these parameters on the scoring split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8346602928647384"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 3, p = 2)\n",
    "knn.fit(X_scoring_train, y_scoring_train)\n",
    "y_scoring_test_predict_knn = knn.predict(X_scoring_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1428,  336],\n",
       "       [ 247, 1483]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_scoring_test, y_scoring_test_predict_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8331425300515168"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_scoring_test, y_scoring_test_predict_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
